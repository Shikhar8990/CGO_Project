#           time             counts unit events
     0.100428354          7,349,966      L1-dcache-load-misses    
     0.100428354         67,318,098      L1-dcache-loads          
     0.200665090          5,659,625      L1-dcache-load-misses    
     0.200665090        111,893,482      L1-dcache-loads          
     0.300819337          6,178,064      L1-dcache-load-misses    
     0.300819337        124,225,987      L1-dcache-loads          
     0.400993798          5,354,733      L1-dcache-load-misses    
     0.400993798        104,159,252      L1-dcache-loads          
     0.501162748          5,231,251      L1-dcache-load-misses    
     0.501162748        144,539,787      L1-dcache-loads          
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0510 10:10:27.392541 129556 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0510 10:10:27.392565 129556 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0510 10:10:27.392568 129556 _caffe.cpp:142] Net('examples/cifar10/cifar10_quick.prototxt', 1, weights='examples/cifar10/cifar10_quick_iter_5000.caffemodel.h5')
I0510 10:10:27.393894 129556 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_quick_test"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "ip2"
  top: "prob"
}
I0510 10:10:27.393939 129556 layer_factory.hpp:77] Creating layer data
I0510 10:10:27.393951 129556 net.cpp:84] Creating Layer data
I0510 10:10:27.393959 129556 net.cpp:380] data -> data
I0510 10:10:27.393975 129556 net.cpp:122] Setting up data
I0510 10:10:27.393981 129556 net.cpp:129] Top shape: 1 3 32 32 (3072)
I0510 10:10:27.393985 129556 net.cpp:137] Memory required for data: 12288
I0510 10:10:27.393987 129556 layer_factory.hpp:77] Creating layer conv1
I0510 10:10:27.393995 129556 net.cpp:84] Creating Layer conv1
I0510 10:10:27.393997 129556 net.cpp:406] conv1 <- data
I0510 10:10:27.394003 129556 net.cpp:380] conv1 -> conv1
I0510 10:10:27.394012 129556 base_conv_layer.cpp:121] Group is 1channel is3number of output is 32
I0510 10:10:27.394028 129556 net.cpp:122] Setting up conv1
I0510 10:10:27.394033 129556 net.cpp:129] Top shape: 1 32 32 32 (32768)
I0510 10:10:27.394035 129556 net.cpp:137] Memory required for data: 143360
I0510 10:10:27.394050 129556 layer_factory.hpp:77] Creating layer pool1
I0510 10:10:27.394057 129556 net.cpp:84] Creating Layer pool1
I0510 10:10:27.394059 129556 net.cpp:406] pool1 <- conv1
I0510 10:10:27.394063 129556 net.cpp:380] pool1 -> pool1
I0510 10:10:27.394071 129556 net.cpp:122] Setting up pool1
I0510 10:10:27.394075 129556 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:27.394078 129556 net.cpp:137] Memory required for data: 176128
I0510 10:10:27.394080 129556 layer_factory.hpp:77] Creating layer relu1
I0510 10:10:27.394084 129556 net.cpp:84] Creating Layer relu1
I0510 10:10:27.394086 129556 net.cpp:406] relu1 <- pool1
I0510 10:10:27.394090 129556 net.cpp:367] relu1 -> pool1 (in-place)
I0510 10:10:27.394094 129556 net.cpp:122] Setting up relu1
I0510 10:10:27.394098 129556 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:27.394100 129556 net.cpp:137] Memory required for data: 208896
I0510 10:10:27.394104 129556 layer_factory.hpp:77] Creating layer conv2
I0510 10:10:27.394109 129556 net.cpp:84] Creating Layer conv2
I0510 10:10:27.394111 129556 net.cpp:406] conv2 <- pool1
I0510 10:10:27.394115 129556 net.cpp:380] conv2 -> conv2
I0510 10:10:27.394122 129556 base_conv_layer.cpp:121] Group is 1channel is32number of output is 32
I0510 10:10:27.394176 129556 net.cpp:122] Setting up conv2
I0510 10:10:27.394181 129556 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:27.394183 129556 net.cpp:137] Memory required for data: 241664
I0510 10:10:27.394189 129556 layer_factory.hpp:77] Creating layer relu2
I0510 10:10:27.394193 129556 net.cpp:84] Creating Layer relu2
I0510 10:10:27.394196 129556 net.cpp:406] relu2 <- conv2
I0510 10:10:27.394199 129556 net.cpp:367] relu2 -> conv2 (in-place)
I0510 10:10:27.394204 129556 net.cpp:122] Setting up relu2
I0510 10:10:27.394207 129556 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:27.394210 129556 net.cpp:137] Memory required for data: 274432
I0510 10:10:27.394212 129556 layer_factory.hpp:77] Creating layer pool2
I0510 10:10:27.394217 129556 net.cpp:84] Creating Layer pool2
I0510 10:10:27.394218 129556 net.cpp:406] pool2 <- conv2
I0510 10:10:27.394222 129556 net.cpp:380] pool2 -> pool2
I0510 10:10:27.394228 129556 net.cpp:122] Setting up pool2
I0510 10:10:27.394232 129556 net.cpp:129] Top shape: 1 32 8 8 (2048)
I0510 10:10:27.394234 129556 net.cpp:137] Memory required for data: 282624
I0510 10:10:27.394237 129556 layer_factory.hpp:77] Creating layer conv3
I0510 10:10:27.394242 129556 net.cpp:84] Creating Layer conv3
I0510 10:10:27.394244 129556 net.cpp:406] conv3 <- pool2
I0510 10:10:27.394248 129556 net.cpp:380] conv3 -> conv3
I0510 10:10:27.394254 129556 base_conv_layer.cpp:121] Group is 1channel is32number of output is 64
I0510 10:10:27.394342 129556 net.cpp:122] Setting up conv3
I0510 10:10:27.394347 129556 net.cpp:129] Top shape: 1 64 8 8 (4096)
I0510 10:10:27.394351 129556 net.cpp:137] Memory required for data: 299008
I0510 10:10:27.394356 129556 layer_factory.hpp:77] Creating layer relu3
I0510 10:10:27.394361 129556 net.cpp:84] Creating Layer relu3
I0510 10:10:27.394363 129556 net.cpp:406] relu3 <- conv3
I0510 10:10:27.394367 129556 net.cpp:367] relu3 -> conv3 (in-place)
I0510 10:10:27.394371 129556 net.cpp:122] Setting up relu3
I0510 10:10:27.394374 129556 net.cpp:129] Top shape: 1 64 8 8 (4096)
I0510 10:10:27.394377 129556 net.cpp:137] Memory required for data: 315392
I0510 10:10:27.394379 129556 layer_factory.hpp:77] Creating layer pool3
I0510 10:10:27.394383 129556 net.cpp:84] Creating Layer pool3
I0510 10:10:27.394385 129556 net.cpp:406] pool3 <- conv3
I0510 10:10:27.394389 129556 net.cpp:380] pool3 -> pool3
I0510 10:10:27.394394 129556 net.cpp:122] Setting up pool3
I0510 10:10:27.394397 129556 net.cpp:129] Top shape: 1 64 4 4 (1024)
I0510 10:10:27.394399 129556 net.cpp:137] Memory required for data: 319488
I0510 10:10:27.394402 129556 layer_factory.hpp:77] Creating layer ip1
I0510 10:10:27.394408 129556 net.cpp:84] Creating Layer ip1
I0510 10:10:27.394412 129556 net.cpp:406] ip1 <- pool3
I0510 10:10:27.394415 129556 net.cpp:380] ip1 -> ip1
I0510 10:10:27.394525 129556 net.cpp:122] Setting up ip1
I0510 10:10:27.394531 129556 net.cpp:129] Top shape: 1 64 (64)
I0510 10:10:27.394532 129556 net.cpp:137] Memory required for data: 319744
I0510 10:10:27.394537 129556 layer_factory.hpp:77] Creating layer ip2
I0510 10:10:27.394541 129556 net.cpp:84] Creating Layer ip2
I0510 10:10:27.394544 129556 net.cpp:406] ip2 <- ip1
I0510 10:10:27.394548 129556 net.cpp:380] ip2 -> ip2
I0510 10:10:27.394557 129556 net.cpp:122] Setting up ip2
I0510 10:10:27.394562 129556 net.cpp:129] Top shape: 1 10 (10)
I0510 10:10:27.394564 129556 net.cpp:137] Memory required for data: 319784
I0510 10:10:27.394570 129556 layer_factory.hpp:77] Creating layer prob
I0510 10:10:27.394574 129556 net.cpp:84] Creating Layer prob
I0510 10:10:27.394577 129556 net.cpp:406] prob <- ip2
I0510 10:10:27.394580 129556 net.cpp:380] prob -> prob
I0510 10:10:27.394587 129556 net.cpp:122] Setting up prob
I0510 10:10:27.394590 129556 net.cpp:129] Top shape: 1 10 (10)
I0510 10:10:27.394593 129556 net.cpp:137] Memory required for data: 319824
I0510 10:10:27.394595 129556 net.cpp:200] prob does not need backward computation.
I0510 10:10:27.394598 129556 net.cpp:200] ip2 does not need backward computation.
I0510 10:10:27.394601 129556 net.cpp:200] ip1 does not need backward computation.
I0510 10:10:27.394603 129556 net.cpp:200] pool3 does not need backward computation.
I0510 10:10:27.394606 129556 net.cpp:200] relu3 does not need backward computation.
I0510 10:10:27.394609 129556 net.cpp:200] conv3 does not need backward computation.
I0510 10:10:27.394611 129556 net.cpp:200] pool2 does not need backward computation.
I0510 10:10:27.394614 129556 net.cpp:200] relu2 does not need backward computation.
I0510 10:10:27.394618 129556 net.cpp:200] conv2 does not need backward computation.
I0510 10:10:27.394619 129556 net.cpp:200] relu1 does not need backward computation.
I0510 10:10:27.394623 129556 net.cpp:200] pool1 does not need backward computation.
I0510 10:10:27.394625 129556 net.cpp:200] conv1 does not need backward computation.
I0510 10:10:27.394629 129556 net.cpp:200] data does not need backward computation.
I0510 10:10:27.394630 129556 net.cpp:242] This network produces output prob
I0510 10:10:27.394637 129556 net.cpp:255] Network initialization done.
I0510 10:10:27.395391 129556 net.cpp:798] Ignoring source layer cifar
I0510 10:10:27.395468 129556 hdf5.cpp:32] Datatype class: H5T_FLOAT
F0510 10:10:27.395479 129556 hdf5.cpp:79] Check failed: blob_dims == blob->shape() Cannot load blob from hdf5; shape mismatch. Source shape is 32 1 5 5 (800) target shape is 32 3 5 5 (2400)
*** Check failure stack trace: ***
     0.601298307          4,182,545      L1-dcache-load-misses    
     0.601298307         83,941,480      L1-dcache-loads          
     0.699587936                  0      L1-dcache-load-misses    
     0.699587936                  0      L1-dcache-loads          
python: Aborted
