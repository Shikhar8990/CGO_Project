#           time             counts unit events
     0.100457930          1,131,722      branch-misses:u          
     0.100457930         47,342,421      branches:u               
     0.200696151          1,628,286      branch-misses:u          
     0.200696151         86,361,119      branches:u               
     0.300861045          1,836,674      branch-misses:u          
     0.300861045         91,561,377      branches:u               
     0.401032465          2,256,308      branch-misses:u          
     0.401032465         82,695,166      branches:u               
     0.501191943          2,474,958      branch-misses:u          
     0.501191943        112,747,988      branches:u               
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0510 10:10:25.172672 129463 _caffe.cpp:139] DEPRECATION WARNING - deprecated use of Python interface
W0510 10:10:25.172696 129463 _caffe.cpp:140] Use this instead (with the named "weights" parameter):
W0510 10:10:25.172699 129463 _caffe.cpp:142] Net('examples/cifar10/cifar10_quick.prototxt', 1, weights='examples/cifar10/cifar10_quick_iter_5000.caffemodel.h5')
I0510 10:10:25.174010 129463 net.cpp:51] Initializing net from parameters: 
name: "CIFAR10_quick_test"
state {
  phase: TEST
  level: 0
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 32
      dim: 32
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 64
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "ip2"
  top: "prob"
}
I0510 10:10:25.174054 129463 layer_factory.hpp:77] Creating layer data
I0510 10:10:25.174067 129463 net.cpp:84] Creating Layer data
I0510 10:10:25.174072 129463 net.cpp:380] data -> data
I0510 10:10:25.174089 129463 net.cpp:122] Setting up data
I0510 10:10:25.174095 129463 net.cpp:129] Top shape: 1 3 32 32 (3072)
I0510 10:10:25.174099 129463 net.cpp:137] Memory required for data: 12288
I0510 10:10:25.174103 129463 layer_factory.hpp:77] Creating layer conv1
I0510 10:10:25.174109 129463 net.cpp:84] Creating Layer conv1
I0510 10:10:25.174113 129463 net.cpp:406] conv1 <- data
I0510 10:10:25.174118 129463 net.cpp:380] conv1 -> conv1
I0510 10:10:25.174126 129463 base_conv_layer.cpp:121] Group is 1channel is3number of output is 32
I0510 10:10:25.174144 129463 net.cpp:122] Setting up conv1
I0510 10:10:25.174149 129463 net.cpp:129] Top shape: 1 32 32 32 (32768)
I0510 10:10:25.174151 129463 net.cpp:137] Memory required for data: 143360
I0510 10:10:25.174166 129463 layer_factory.hpp:77] Creating layer pool1
I0510 10:10:25.174172 129463 net.cpp:84] Creating Layer pool1
I0510 10:10:25.174175 129463 net.cpp:406] pool1 <- conv1
I0510 10:10:25.174180 129463 net.cpp:380] pool1 -> pool1
I0510 10:10:25.174187 129463 net.cpp:122] Setting up pool1
I0510 10:10:25.174191 129463 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:25.174193 129463 net.cpp:137] Memory required for data: 176128
I0510 10:10:25.174196 129463 layer_factory.hpp:77] Creating layer relu1
I0510 10:10:25.174201 129463 net.cpp:84] Creating Layer relu1
I0510 10:10:25.174202 129463 net.cpp:406] relu1 <- pool1
I0510 10:10:25.174206 129463 net.cpp:367] relu1 -> pool1 (in-place)
I0510 10:10:25.174211 129463 net.cpp:122] Setting up relu1
I0510 10:10:25.174214 129463 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:25.174216 129463 net.cpp:137] Memory required for data: 208896
I0510 10:10:25.174218 129463 layer_factory.hpp:77] Creating layer conv2
I0510 10:10:25.174224 129463 net.cpp:84] Creating Layer conv2
I0510 10:10:25.174226 129463 net.cpp:406] conv2 <- pool1
I0510 10:10:25.174230 129463 net.cpp:380] conv2 -> conv2
I0510 10:10:25.174237 129463 base_conv_layer.cpp:121] Group is 1channel is32number of output is 32
I0510 10:10:25.174290 129463 net.cpp:122] Setting up conv2
I0510 10:10:25.174296 129463 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:25.174299 129463 net.cpp:137] Memory required for data: 241664
I0510 10:10:25.174304 129463 layer_factory.hpp:77] Creating layer relu2
I0510 10:10:25.174309 129463 net.cpp:84] Creating Layer relu2
I0510 10:10:25.174311 129463 net.cpp:406] relu2 <- conv2
I0510 10:10:25.174315 129463 net.cpp:367] relu2 -> conv2 (in-place)
I0510 10:10:25.174319 129463 net.cpp:122] Setting up relu2
I0510 10:10:25.174324 129463 net.cpp:129] Top shape: 1 32 16 16 (8192)
I0510 10:10:25.174325 129463 net.cpp:137] Memory required for data: 274432
I0510 10:10:25.174327 129463 layer_factory.hpp:77] Creating layer pool2
I0510 10:10:25.174331 129463 net.cpp:84] Creating Layer pool2
I0510 10:10:25.174335 129463 net.cpp:406] pool2 <- conv2
I0510 10:10:25.174337 129463 net.cpp:380] pool2 -> pool2
I0510 10:10:25.174343 129463 net.cpp:122] Setting up pool2
I0510 10:10:25.174346 129463 net.cpp:129] Top shape: 1 32 8 8 (2048)
I0510 10:10:25.174350 129463 net.cpp:137] Memory required for data: 282624
I0510 10:10:25.174351 129463 layer_factory.hpp:77] Creating layer conv3
I0510 10:10:25.174356 129463 net.cpp:84] Creating Layer conv3
I0510 10:10:25.174358 129463 net.cpp:406] conv3 <- pool2
I0510 10:10:25.174362 129463 net.cpp:380] conv3 -> conv3
I0510 10:10:25.174368 129463 base_conv_layer.cpp:121] Group is 1channel is32number of output is 64
I0510 10:10:25.174454 129463 net.cpp:122] Setting up conv3
I0510 10:10:25.174459 129463 net.cpp:129] Top shape: 1 64 8 8 (4096)
I0510 10:10:25.174463 129463 net.cpp:137] Memory required for data: 299008
I0510 10:10:25.174468 129463 layer_factory.hpp:77] Creating layer relu3
I0510 10:10:25.174474 129463 net.cpp:84] Creating Layer relu3
I0510 10:10:25.174475 129463 net.cpp:406] relu3 <- conv3
I0510 10:10:25.174479 129463 net.cpp:367] relu3 -> conv3 (in-place)
I0510 10:10:25.174484 129463 net.cpp:122] Setting up relu3
I0510 10:10:25.174486 129463 net.cpp:129] Top shape: 1 64 8 8 (4096)
I0510 10:10:25.174489 129463 net.cpp:137] Memory required for data: 315392
I0510 10:10:25.174491 129463 layer_factory.hpp:77] Creating layer pool3
I0510 10:10:25.174495 129463 net.cpp:84] Creating Layer pool3
I0510 10:10:25.174497 129463 net.cpp:406] pool3 <- conv3
I0510 10:10:25.174501 129463 net.cpp:380] pool3 -> pool3
I0510 10:10:25.174506 129463 net.cpp:122] Setting up pool3
I0510 10:10:25.174510 129463 net.cpp:129] Top shape: 1 64 4 4 (1024)
I0510 10:10:25.174511 129463 net.cpp:137] Memory required for data: 319488
I0510 10:10:25.174513 129463 layer_factory.hpp:77] Creating layer ip1
I0510 10:10:25.174520 129463 net.cpp:84] Creating Layer ip1
I0510 10:10:25.174523 129463 net.cpp:406] ip1 <- pool3
I0510 10:10:25.174527 129463 net.cpp:380] ip1 -> ip1
I0510 10:10:25.174635 129463 net.cpp:122] Setting up ip1
I0510 10:10:25.174641 129463 net.cpp:129] Top shape: 1 64 (64)
I0510 10:10:25.174644 129463 net.cpp:137] Memory required for data: 319744
I0510 10:10:25.174649 129463 layer_factory.hpp:77] Creating layer ip2
I0510 10:10:25.174652 129463 net.cpp:84] Creating Layer ip2
I0510 10:10:25.174656 129463 net.cpp:406] ip2 <- ip1
I0510 10:10:25.174659 129463 net.cpp:380] ip2 -> ip2
I0510 10:10:25.174669 129463 net.cpp:122] Setting up ip2
I0510 10:10:25.174672 129463 net.cpp:129] Top shape: 1 10 (10)
I0510 10:10:25.174675 129463 net.cpp:137] Memory required for data: 319784
I0510 10:10:25.174680 129463 layer_factory.hpp:77] Creating layer prob
I0510 10:10:25.174685 129463 net.cpp:84] Creating Layer prob
I0510 10:10:25.174687 129463 net.cpp:406] prob <- ip2
I0510 10:10:25.174690 129463 net.cpp:380] prob -> prob
I0510 10:10:25.174696 129463 net.cpp:122] Setting up prob
I0510 10:10:25.174700 129463 net.cpp:129] Top shape: 1 10 (10)
I0510 10:10:25.174702 129463 net.cpp:137] Memory required for data: 319824
I0510 10:10:25.174705 129463 net.cpp:200] prob does not need backward computation.
I0510 10:10:25.174708 129463 net.cpp:200] ip2 does not need backward computation.
I0510 10:10:25.174710 129463 net.cpp:200] ip1 does not need backward computation.
I0510 10:10:25.174713 129463 net.cpp:200] pool3 does not need backward computation.
I0510 10:10:25.174716 129463 net.cpp:200] relu3 does not need backward computation.
I0510 10:10:25.174720 129463 net.cpp:200] conv3 does not need backward computation.
I0510 10:10:25.174721 129463 net.cpp:200] pool2 does not need backward computation.
I0510 10:10:25.174724 129463 net.cpp:200] relu2 does not need backward computation.
I0510 10:10:25.174727 129463 net.cpp:200] conv2 does not need backward computation.
I0510 10:10:25.174729 129463 net.cpp:200] relu1 does not need backward computation.
I0510 10:10:25.174732 129463 net.cpp:200] pool1 does not need backward computation.
I0510 10:10:25.174736 129463 net.cpp:200] conv1 does not need backward computation.
I0510 10:10:25.174738 129463 net.cpp:200] data does not need backward computation.
I0510 10:10:25.174741 129463 net.cpp:242] This network produces output prob
I0510 10:10:25.174747 129463 net.cpp:255] Network initialization done.
I0510 10:10:25.175501 129463 net.cpp:798] Ignoring source layer cifar
I0510 10:10:25.175576 129463 hdf5.cpp:32] Datatype class: H5T_FLOAT
F0510 10:10:25.175586 129463 hdf5.cpp:79] Check failed: blob_dims == blob->shape() Cannot load blob from hdf5; shape mismatch. Source shape is 32 1 5 5 (800) target shape is 32 3 5 5 (2400)
*** Check failure stack trace: ***
     0.601336567          1,152,407      branch-misses:u          
     0.601336567         85,536,692      branches:u               
     0.701483552      <not counted>      branch-misses:u          
     0.701483552      <not counted>      branches:u               
     0.759282693                  0      branch-misses:u          
     0.759282693                  0      branches:u               
python: Aborted
